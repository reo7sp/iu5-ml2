{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 5\n",
    "\n",
    "## Предобработка и классификация текстовых данных.\n",
    "\n",
    "**Цель лабораторной работы**: изучение методов предобработки и классификации текстовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xZpoo218Y2Ay"
   },
   "outputs": [],
   "source": [
    "text = '''С другой стороны социально-экономическое развитие влечет за собой процесс внедрения и модернизации модели развития. \n",
    "Разнообразный и богатый опыт начало повседневной работы по формированию позиции представляет собой интересный эксперимент проверки направлений прогрессивного развития. \n",
    "Повседневная практика показывает, что новая модель организационной деятельности играет важную роль в формировании модели развития.'''\n",
    "text2 = 'Россия или Российская Федерация — государство в Восточной Европе и Северной Азии со столицей в городе Москва.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D29cTbU76Ef"
   },
   "source": [
    "# Задача токенизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "g976JvjQaEX-"
   },
   "outputs": [],
   "source": [
    "from razdel import tokenize, sentenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZ5RiWNraFGc",
    "outputId": "4a5b8470-3f73-4d58-c85b-6b4fd8d49677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 1, 'С'),\n",
       " Substring(2, 8, 'другой'),\n",
       " Substring(9, 16, 'стороны'),\n",
       " Substring(17, 40, 'социально-экономическое'),\n",
       " Substring(41, 49, 'развитие'),\n",
       " Substring(50, 56, 'влечет'),\n",
       " Substring(57, 59, 'за'),\n",
       " Substring(60, 65, 'собой'),\n",
       " Substring(66, 73, 'процесс'),\n",
       " Substring(74, 83, 'внедрения'),\n",
       " Substring(84, 85, 'и'),\n",
       " Substring(86, 98, 'модернизации'),\n",
       " Substring(99, 105, 'модели'),\n",
       " Substring(106, 114, 'развития'),\n",
       " Substring(114, 115, '.'),\n",
       " Substring(117, 130, 'Разнообразный'),\n",
       " Substring(131, 132, 'и'),\n",
       " Substring(133, 140, 'богатый'),\n",
       " Substring(141, 145, 'опыт'),\n",
       " Substring(146, 152, 'начало'),\n",
       " Substring(153, 165, 'повседневной'),\n",
       " Substring(166, 172, 'работы'),\n",
       " Substring(173, 175, 'по'),\n",
       " Substring(176, 188, 'формированию'),\n",
       " Substring(189, 196, 'позиции'),\n",
       " Substring(197, 209, 'представляет'),\n",
       " Substring(210, 215, 'собой'),\n",
       " Substring(216, 226, 'интересный'),\n",
       " Substring(227, 238, 'эксперимент'),\n",
       " Substring(239, 247, 'проверки'),\n",
       " Substring(248, 259, 'направлений'),\n",
       " Substring(260, 274, 'прогрессивного'),\n",
       " Substring(275, 283, 'развития'),\n",
       " Substring(283, 284, '.'),\n",
       " Substring(286, 298, 'Повседневная'),\n",
       " Substring(299, 307, 'практика'),\n",
       " Substring(308, 318, 'показывает'),\n",
       " Substring(318, 319, ','),\n",
       " Substring(320, 323, 'что'),\n",
       " Substring(324, 329, 'новая'),\n",
       " Substring(330, 336, 'модель'),\n",
       " Substring(337, 352, 'организационной'),\n",
       " Substring(353, 365, 'деятельности'),\n",
       " Substring(366, 372, 'играет'),\n",
       " Substring(373, 379, 'важную'),\n",
       " Substring(380, 384, 'роль'),\n",
       " Substring(385, 386, 'в'),\n",
       " Substring(387, 399, 'формировании'),\n",
       " Substring(400, 406, 'модели'),\n",
       " Substring(407, 415, 'развития'),\n",
       " Substring(415, 416, '.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_tok_text = list(tokenize(text))\n",
    "n_tok_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "US4-R7DHaP2-",
    "outputId": "c837f902-1579-4d96-ae97-3095691c0e60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['С',\n",
       " 'другой',\n",
       " 'стороны',\n",
       " 'социально-экономическое',\n",
       " 'развитие',\n",
       " 'влечет',\n",
       " 'за',\n",
       " 'собой',\n",
       " 'процесс',\n",
       " 'внедрения',\n",
       " 'и',\n",
       " 'модернизации',\n",
       " 'модели',\n",
       " 'развития',\n",
       " '.',\n",
       " 'Разнообразный',\n",
       " 'и',\n",
       " 'богатый',\n",
       " 'опыт',\n",
       " 'начало',\n",
       " 'повседневной',\n",
       " 'работы',\n",
       " 'по',\n",
       " 'формированию',\n",
       " 'позиции',\n",
       " 'представляет',\n",
       " 'собой',\n",
       " 'интересный',\n",
       " 'эксперимент',\n",
       " 'проверки',\n",
       " 'направлений',\n",
       " 'прогрессивного',\n",
       " 'развития',\n",
       " '.',\n",
       " 'Повседневная',\n",
       " 'практика',\n",
       " 'показывает',\n",
       " ',',\n",
       " 'что',\n",
       " 'новая',\n",
       " 'модель',\n",
       " 'организационной',\n",
       " 'деятельности',\n",
       " 'играет',\n",
       " 'важную',\n",
       " 'роль',\n",
       " 'в',\n",
       " 'формировании',\n",
       " 'модели',\n",
       " 'развития',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in n_tok_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3qQdSq5aQqO",
    "outputId": "946fdfbd-151f-47e5-f161-c3a49c112c11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0,\n",
       "           115,\n",
       "           'С другой стороны социально-экономическое развитие влечет за собой процесс внедрения и модернизации модели развития.'),\n",
       " Substring(117,\n",
       "           284,\n",
       "           'Разнообразный и богатый опыт начало повседневной работы по формированию позиции представляет собой интересный эксперимент проверки направлений прогрессивного развития.'),\n",
       " Substring(286,\n",
       "           416,\n",
       "           'Повседневная практика показывает, что новая модель организационной деятельности играет важную роль в формировании модели развития.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_text = list(sentenize(text))\n",
    "n_sen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fSsI-IsGjk9i",
    "outputId": "dd7f06fa-bd56-4df3-9a00-0ead10b03e61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['С другой стороны социально-экономическое развитие влечет за собой процесс внедрения и модернизации модели развития.',\n",
       "  'Разнообразный и богатый опыт начало повседневной работы по формированию позиции представляет собой интересный эксперимент проверки направлений прогрессивного развития.',\n",
       "  'Повседневная практика показывает, что новая модель организационной деятельности играет важную роль в формировании модели развития.'],\n",
       " 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in n_sen_text], len([_.text for _ in n_sen_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1-LaovsnjtZk"
   },
   "outputs": [],
   "source": [
    "# Этот вариант токенизации нужен для последующей обработки\n",
    "def n_sentenize(text):\n",
    "    n_sen_chunk = []\n",
    "    for sent in sentenize(text):\n",
    "        tokens = [_.text for _ in tokenize(sent.text)]\n",
    "        n_sen_chunk.append(tokens)\n",
    "    return n_sen_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9y8VzzhjvHt",
    "outputId": "39a8b6cf-d507-4167-e020-cda9513e5d9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['С',\n",
       "  'другой',\n",
       "  'стороны',\n",
       "  'социально-экономическое',\n",
       "  'развитие',\n",
       "  'влечет',\n",
       "  'за',\n",
       "  'собой',\n",
       "  'процесс',\n",
       "  'внедрения',\n",
       "  'и',\n",
       "  'модернизации',\n",
       "  'модели',\n",
       "  'развития',\n",
       "  '.'],\n",
       " ['Разнообразный',\n",
       "  'и',\n",
       "  'богатый',\n",
       "  'опыт',\n",
       "  'начало',\n",
       "  'повседневной',\n",
       "  'работы',\n",
       "  'по',\n",
       "  'формированию',\n",
       "  'позиции',\n",
       "  'представляет',\n",
       "  'собой',\n",
       "  'интересный',\n",
       "  'эксперимент',\n",
       "  'проверки',\n",
       "  'направлений',\n",
       "  'прогрессивного',\n",
       "  'развития',\n",
       "  '.'],\n",
       " ['Повседневная',\n",
       "  'практика',\n",
       "  'показывает',\n",
       "  ',',\n",
       "  'что',\n",
       "  'новая',\n",
       "  'модель',\n",
       "  'организационной',\n",
       "  'деятельности',\n",
       "  'играет',\n",
       "  'важную',\n",
       "  'роль',\n",
       "  'в',\n",
       "  'формировании',\n",
       "  'модели',\n",
       "  'развития',\n",
       "  '.']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_chunk = n_sentenize(text)\n",
    "n_sen_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zn4MxoHwocQ8",
    "outputId": "27a75cac-79d3-4b45-b5a1-64e9c2829272"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Россия',\n",
       "  'или',\n",
       "  'Российская',\n",
       "  'Федерация',\n",
       "  '—',\n",
       "  'государство',\n",
       "  'в',\n",
       "  'Восточной',\n",
       "  'Европе',\n",
       "  'и',\n",
       "  'Северной',\n",
       "  'Азии',\n",
       "  'со',\n",
       "  'столицей',\n",
       "  'в',\n",
       "  'городе',\n",
       "  'Москва',\n",
       "  '.']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sen_chunk_2 = n_sentenize(text2)\n",
    "n_sen_chunk_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWPyU6o68IxP"
   },
   "source": [
    "# Частеречная разметка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OJ5AC_rBj7Au"
   },
   "outputs": [],
   "source": [
    "from navec import Navec\n",
    "from slovnet import Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "GnUNaqiGj9x4"
   },
   "outputs": [],
   "source": [
    "# Файл необходимо скачать по ссылке https://github.com/natasha/navec#downloads\n",
    "navec = Navec.load('navec_news_v1_1B_250K_300d_100q.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "JIbJX44Ck5TR"
   },
   "outputs": [],
   "source": [
    "# Файл необходимо скачать по ссылке https://github.com/natasha/slovnet#downloads\n",
    "n_morph = Morph.load('slovnet_morph_news_v1.tar', batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "VGmz2S2OlB-x"
   },
   "outputs": [],
   "source": [
    "morph_res = n_morph.navec(navec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "PHeplM8slDbu"
   },
   "outputs": [],
   "source": [
    "def print_pos(markup):\n",
    "    for token in markup.tokens:\n",
    "        print('{} - {}'.format(token.text, token.tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ox7jury8lGBs",
    "outputId": "63f54e6d-4298-4a02-aa67-3429ae04a63c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С - ADP\n",
      "другой - ADJ|Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\n",
      "стороны - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "социально-экономическое - ADJ|Case=Nom|Degree=Pos|Gender=Neut|Number=Sing\n",
      "развитие - NOUN|Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing\n",
      "влечет - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "за - ADP\n",
      "собой - PRON|Case=Ins\n",
      "процесс - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
      "внедрения - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
      "и - CCONJ\n",
      "модернизации - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "модели - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "развития - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
      ". - PUNCT\n",
      "Разнообразный - ADJ|Case=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
      "и - CCONJ\n",
      "богатый - ADJ|Case=Nom|Degree=Pos|Gender=Masc|Number=Sing\n",
      "опыт - NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "начало - NOUN|Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing\n",
      "повседневной - ADJ|Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\n",
      "работы - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "по - ADP\n",
      "формированию - NOUN|Animacy=Inan|Case=Dat|Gender=Neut|Number=Sing\n",
      "позиции - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "представляет - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "собой - PRON|Case=Ins\n",
      "интересный - ADJ|Animacy=Inan|Case=Acc|Degree=Pos|Gender=Masc|Number=Sing\n",
      "эксперимент - NOUN|Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing\n",
      "проверки - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "направлений - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Plur\n",
      "прогрессивного - ADJ|Case=Gen|Degree=Pos|Gender=Neut|Number=Sing\n",
      "развития - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
      ". - PUNCT\n",
      "Повседневная - ADJ|Case=Nom|Degree=Pos|Gender=Fem|Number=Sing\n",
      "практика - NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
      "показывает - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      ", - PUNCT\n",
      "что - SCONJ\n",
      "новая - ADJ|Case=Nom|Degree=Pos|Gender=Fem|Number=Sing\n",
      "модель - NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
      "организационной - ADJ|Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\n",
      "деятельности - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "играет - VERB|Aspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act\n",
      "важную - ADJ|Case=Acc|Degree=Pos|Gender=Fem|Number=Sing\n",
      "роль - NOUN|Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing\n",
      "в - ADP\n",
      "формировании - NOUN|Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing\n",
      "модели - NOUN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "развития - NOUN|Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing\n",
      ". - PUNCT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_text_markup = list(_ for _ in n_morph.map(n_sen_chunk))\n",
    "[print_pos(x) for x in n_text_markup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lR8begRoh2Y",
    "outputId": "4ab7bfc1-54b3-4d3b-d465-ee9798da147b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Россия - PROPN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
      "или - CCONJ\n",
      "Российская - ADJ|Case=Nom|Degree=Pos|Gender=Fem|Number=Sing\n",
      "Федерация - PROPN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
      "— - PUNCT\n",
      "государство - NOUN|Animacy=Inan|Case=Nom|Gender=Neut|Number=Sing\n",
      "в - ADP\n",
      "Восточной - ADJ|Case=Loc|Degree=Pos|Gender=Fem|Number=Sing\n",
      "Европе - PROPN|Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing\n",
      "и - CCONJ\n",
      "Северной - ADJ|Case=Gen|Degree=Pos|Gender=Fem|Number=Sing\n",
      "Азии - PROPN|Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing\n",
      "со - ADP\n",
      "столицей - NOUN|Animacy=Inan|Case=Ins|Gender=Fem|Number=Sing\n",
      "в - ADP\n",
      "городе - NOUN|Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing\n",
      "Москва - PROPN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
      ". - PUNCT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_text2_markup = list(n_morph.map(n_sen_chunk_2))\n",
    "[print_pos(x) for x in n_text2_markup]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0okcggK8RyX"
   },
   "source": [
    "# Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "MwcHLMPxlZbv"
   },
   "outputs": [],
   "source": [
    "from natasha import Doc, Segmenter, NewsEmbedding, NewsMorphTagger, MorphVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "QiZyPQqClbSu"
   },
   "outputs": [],
   "source": [
    "def n_lemmatize(text):\n",
    "    emb = NewsEmbedding()\n",
    "    morph_tagger = NewsMorphTagger(emb)\n",
    "    segmenter = Segmenter()\n",
    "    morph_vocab = MorphVocab()\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_vfR7milc_L",
    "outputId": "ca2d7e3b-45f3-4bd9-9dfe-11e9b0645584"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'С': 'с',\n",
       " 'другой': 'другой',\n",
       " 'стороны': 'сторона',\n",
       " 'социально-экономическое': 'социально-экономический',\n",
       " 'развитие': 'развитие',\n",
       " 'влечет': 'влечь',\n",
       " 'за': 'за',\n",
       " 'собой': 'себя',\n",
       " 'процесс': 'процесс',\n",
       " 'внедрения': 'внедрение',\n",
       " 'и': 'и',\n",
       " 'модернизации': 'модернизация',\n",
       " 'модели': 'модель',\n",
       " 'развития': 'развитие',\n",
       " '.': '.',\n",
       " 'Разнообразный': 'разнообразный',\n",
       " 'богатый': 'богатый',\n",
       " 'опыт': 'опыт',\n",
       " 'начало': 'начало',\n",
       " 'повседневной': 'повседневный',\n",
       " 'работы': 'работа',\n",
       " 'по': 'по',\n",
       " 'формированию': 'формирование',\n",
       " 'позиции': 'позиция',\n",
       " 'представляет': 'представлять',\n",
       " 'интересный': 'интересный',\n",
       " 'эксперимент': 'эксперимент',\n",
       " 'проверки': 'проверка',\n",
       " 'направлений': 'направление',\n",
       " 'прогрессивного': 'прогрессивный',\n",
       " 'Повседневная': 'повседневный',\n",
       " 'практика': 'практика',\n",
       " 'показывает': 'показывать',\n",
       " ',': ',',\n",
       " 'что': 'что',\n",
       " 'новая': 'новый',\n",
       " 'модель': 'модель',\n",
       " 'организационной': 'организационный',\n",
       " 'деятельности': 'деятельность',\n",
       " 'играет': 'играть',\n",
       " 'важную': 'важный',\n",
       " 'роль': 'роль',\n",
       " 'в': 'в',\n",
       " 'формировании': 'формирование'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_doc = n_lemmatize(text)\n",
    "{_.text: _.lemma for _ in n_doc.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ctQlhapPoooX",
    "outputId": "366fcc77-b0ee-4377-e961-a0899fb68d39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Россия': 'россия',\n",
       " 'или': 'или',\n",
       " 'Российская': 'российский',\n",
       " 'Федерация': 'федерация',\n",
       " '—': '—',\n",
       " 'государство': 'государство',\n",
       " 'в': 'в',\n",
       " 'Восточной': 'восточный',\n",
       " 'Европе': 'европа',\n",
       " 'и': 'и',\n",
       " 'Северной': 'северный',\n",
       " 'Азии': 'азия',\n",
       " 'со': 'с',\n",
       " 'столицей': 'столица',\n",
       " 'городе': 'город',\n",
       " 'Москва': 'москва',\n",
       " '.': '.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_doc2 = n_lemmatize(text2)\n",
    "{_.text: _.lemma for _ in n_doc2.tokens}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGiHQ5nV8YHS"
   },
   "source": [
    "# Выделение (распознавание) именованных сущностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "CX1Jn2LjllO4"
   },
   "outputs": [],
   "source": [
    "from slovnet import NER\n",
    "from ipymarkup import show_span_ascii_markup as show_markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "6jR1CB3clmoO"
   },
   "outputs": [],
   "source": [
    "ner = NER.load('slovnet_ner_news_v1.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "EfcXKkyLlo_f"
   },
   "outputs": [],
   "source": [
    "ner_res = ner.navec(navec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUkgF6nVlrLY",
    "outputId": "11e31ff2-d254-4cee-d0a6-04098014ce7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpanMarkup(\n",
       "    text='Россия или Российская Федерация — государство в Восточной Европе и Северной Азии со столицей в городе Москва.',\n",
       "    spans=[Span(\n",
       "         start=0,\n",
       "         stop=6,\n",
       "         type='LOC'\n",
       "     ),\n",
       "     Span(\n",
       "         start=11,\n",
       "         stop=31,\n",
       "         type='LOC'\n",
       "     ),\n",
       "     Span(\n",
       "         start=48,\n",
       "         stop=64,\n",
       "         type='LOC'\n",
       "     ),\n",
       "     Span(\n",
       "         start=67,\n",
       "         stop=80,\n",
       "         type='LOC'\n",
       "     ),\n",
       "     Span(\n",
       "         start=102,\n",
       "         stop=108,\n",
       "         type='LOC'\n",
       "     )]\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markup_ner = ner(text2)\n",
    "markup_ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iy-71aTplrGm",
    "outputId": "c4bf89f2-6a2e-43ea-e503-cab3008e2f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Россия или Российская Федерация — государство в Восточной Европе и \n",
      "LOC───     LOC─────────────────                 LOC─────────────   \n",
      "Северной Азии со столицей в городе Москва.\n",
      "LOC──────────                      LOC─── \n"
     ]
    }
   ],
   "source": [
    "show_markup(markup_ner.text, markup_ner.spans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1EEBFmk8ddx"
   },
   "source": [
    "# Разбор предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "w07LI_cdnt3A"
   },
   "outputs": [],
   "source": [
    "from natasha import NewsSyntaxParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "ad3aEUqunyFr"
   },
   "outputs": [],
   "source": [
    "emb = NewsEmbedding()\n",
    "syntax_parser = NewsSyntaxParser(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbFuGGMinzZu",
    "outputId": "76afeaf7-0a44-420b-a290-ddc026b46f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ┌──► С                       case\n",
      "      │ ┌► другой                  amod\n",
      "    ┌►└─└─ стороны                 obl\n",
      "    │   ┌► социально-экономическое amod\n",
      "    │ ┌►└─ развитие                nsubj\n",
      "┌─┌─└─└─── влечет                  \n",
      "│ │ │   ┌► за                      case\n",
      "│ │ └──►└─ собой                   obl\n",
      "│ └────►┌─ процесс                 obj\n",
      "│   ┌─┌─└► внедрения               nmod\n",
      "│   │ │ ┌► и                       cc\n",
      "│   │ └►└─ модернизации            conj\n",
      "│   └──►┌─ модели                  nmod\n",
      "│       └► развития                nmod\n",
      "└────────► .                       punct\n"
     ]
    }
   ],
   "source": [
    "n_doc.parse_syntax(syntax_parser)\n",
    "n_doc.sents[0].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yc4OlSa1n08h",
    "outputId": "b3d22198-587b-48f5-82fc-d3023cefedf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌──► Разнообразный  amod\n",
      "        │ ┌► и              cc\n",
      "        │ └─ богатый        \n",
      "┌──────►└─── опыт           conj\n",
      "│   ┌──►┌─── начало         obj\n",
      "│   │   │ ┌► повседневной   amod\n",
      "│   │ ┌─└►└─ работы         nmod\n",
      "│   │ │   ┌► по             case\n",
      "│   │ └►┌─└─ формированию   nmod\n",
      "│   │   └──► позиции        nmod\n",
      "│ ┌─└───┌─┌─ представляет   \n",
      "│ │     │ └► собой          fixed\n",
      "│ │     │ ┌► интересный     amod\n",
      "└─│     └►└─ эксперимент    obj\n",
      "  │     └►┌─ проверки       nmod\n",
      "  │     ┌─└► направлений    nmod\n",
      "  │     │ ┌► прогрессивного amod\n",
      "  │     └►└─ развития       nmod\n",
      "  └────────► .              punct\n"
     ]
    }
   ],
   "source": [
    "n_doc.parse_syntax(syntax_parser)\n",
    "n_doc.sents[1].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T7a2nHbUn9-4",
    "outputId": "e1759489-0c9d-49ff-bb42-8dbac8d8125f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ┌► Повседневная    amod\n",
      "          ┌►└─ практика        nsubj\n",
      "┌─┌───────└─── показывает      \n",
      "│ │ ┌────────► ,               punct\n",
      "│ │ │ ┌──────► что             mark\n",
      "│ │ │ │     ┌► новая           amod\n",
      "│ │ │ │ ┌►┌─└─ модель          nsubj\n",
      "│ │ │ │ │ │ ┌► организационной amod\n",
      "│ │ │ │ │ └►└─ деятельности    nmod\n",
      "│ └►└─└─└─┌─── играет          ccomp\n",
      "│         │ ┌► важную          amod\n",
      "│       ┌─└►└─ роль            obj\n",
      "│       │   ┌► в               case\n",
      "│       └►┌─└─ формировании    nmod\n",
      "│         └►┌─ модели          nmod\n",
      "│           └► развития        nmod\n",
      "└────────────► .               punct\n"
     ]
    }
   ],
   "source": [
    "n_doc.parse_syntax(syntax_parser)\n",
    "n_doc.sents[2].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QcEdIjQoEX9",
    "outputId": "8ab65083-d8ca-471c-8704-3d59b1692328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ┌────► Россия      nsubj\n",
      "      │ ┌──► или         cc\n",
      "      │ │ ┌► Российская  amod\n",
      "      │ └─└─ Федерация   \n",
      "      │   ┌► —           punct\n",
      "┌─┌───└───└─ государство \n",
      "│ │   │ ┌──► в           case\n",
      "│ │   │ │ ┌► Восточной   amod\n",
      "│ │ ┌─└►└─└─ Европе      nmod\n",
      "│ │ │   ┌──► и           cc\n",
      "│ │ │   │ ┌► Северной    amod\n",
      "│ │ └──►└─└─ Азии        conj\n",
      "│ │       ┌► со          case\n",
      "│ └────►┌─└─ столицей    nmod\n",
      "│       │ ┌► в           case\n",
      "│       └►└─ городе      nmod\n",
      "│       └──► Москва      appos\n",
      "└──────────► .           punct\n"
     ]
    }
   ],
   "source": [
    "n_doc2.parse_syntax(syntax_parser)\n",
    "n_doc2.sents[0].syntax.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "-c2XPKKOq7Wu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, median_absolute_error, r2_score \n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline \n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAzmgaJ_80sH"
   },
   "source": [
    "# Векторизация текста на основе модели \"мешка слов\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "VLoXLDqzq4Ku"
   },
   "outputs": [],
   "source": [
    "categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
    "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
    "data = newsgroups['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "42Wh-CynrkGj"
   },
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esrSY6qXrleU",
    "outputId": "2c18f7b7-2900-4f08-9774-a1205ce3553e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество сформированных признаков - 33448\n"
     ]
    }
   ],
   "source": [
    "vocabVect = CountVectorizer()\n",
    "vocabVect.fit(data)\n",
    "corpusVocab = vocabVect.vocabulary_\n",
    "print('Количество сформированных признаков - {}'.format(len(corpusVocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UA7wvzZsJxl",
    "outputId": "2834a405-4f73-495a-9fbc-2f861e6a9b1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrmendel=22213\n",
      "unix=31462\n",
      "amherst=5287\n",
      "edu=12444\n",
      "nathaniel=21624\n",
      "mendell=20477\n",
      "subject=29220\n",
      "re=25369\n",
      "bike=6898\n"
     ]
    }
   ],
   "source": [
    "for i in list(corpusVocab)[1:10]:\n",
    "    print('{}={}'.format(i, corpusVocab[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_MD1mfu9BUt"
   },
   "source": [
    "# Использование класса CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "EOcZ0afBs98g"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2380x33448 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 335176 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = vocabVect.transform(data)\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "olYUOhsstEZ1",
    "outputId": "d5da9572-c1ff-44ae-e3c9-0e55e72079cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [2, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-56OfvNtH9r",
    "outputId": "e630591c-5939-487d-cc50-ab599877233d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33448"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Размер нулевой строки\n",
    "len(test_features.todense()[0].getA1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8lQND6-DtKEh",
    "outputId": "34af4962-da03-4e1f-91b8-3ccdbb923bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "# Непустые значения нулевой строки\n",
    "print([i for i in test_features.todense()[0].getA1() if i>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZMU_R7GtS6d",
    "outputId": "be131d23-fd62-4c6f-f394-73eba47ed5c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnikolskiy/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '0000000004',\n",
       " '0000000005',\n",
       " '0000000667',\n",
       " '0000001200',\n",
       " '0001',\n",
       " '00014',\n",
       " '0002']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabVect.get_feature_names()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsJo3ST09MHT"
   },
   "source": [
    "# Решение задачи анализа тональности текста на основе модели \"мешка слов\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "VV9Gdq0At4yY"
   },
   "outputs": [],
   "source": [
    "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
    "    for v in vectorizers_list:\n",
    "        for c in classifiers_list:\n",
    "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
    "            score = cross_val_score(pipeline1, newsgroups['data'], newsgroups['target'], scoring='accuracy', cv=3).mean()\n",
    "            print('Векторизация - {}'.format(v))\n",
    "            print('Модель для классификации - {}'.format(c))\n",
    "            print('Accuracy = {}'.format(score))\n",
    "            print('===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdDlkVmyt9uu",
    "outputId": "c9be2ed5-4273-4f68-db02-c1309678fe4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnikolskiy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dnikolskiy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dnikolskiy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
      "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
      "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
      "                            '0005111312': 11, '0005111312na1em': 12,\n",
      "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
      "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
      "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
      "                            '001813': 24, '002': 25, '002222': 26,\n",
      "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
      "Модель для классификации - LogisticRegression(C=3.0)\n",
      "Accuracy = 0.9382336841146768\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
      "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
      "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
      "                            '0005111312': 11, '0005111312na1em': 12,\n",
      "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
      "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
      "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
      "                            '001813': 24, '002': 25, '002222': 26,\n",
      "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
      "Модель для классификации - LinearSVC()\n",
      "Accuracy = 0.9453742497059174\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '000': 1, '0000': 2, '0000000004': 3,\n",
      "                            '0000000005': 4, '0000000667': 5, '0000001200': 6,\n",
      "                            '0001': 7, '00014': 8, '0002': 9, '0003': 10,\n",
      "                            '0005111312': 11, '0005111312na1em': 12,\n",
      "                            '00072': 13, '000851': 14, '000rpm': 15,\n",
      "                            '000th': 16, '001': 17, '0010': 18, '001004': 19,\n",
      "                            '0011': 20, '001211': 21, '0013': 22, '001642': 23,\n",
      "                            '001813': 24, '002': 25, '002222': 26,\n",
      "                            '002251w': 27, '0023': 28, '002937': 29, ...})\n",
      "Модель для классификации - KNeighborsClassifier()\n",
      "Accuracy = 0.6655358653541747\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab)]\n",
    "classifiers_list = [LogisticRegression(C=3.0), LinearSVC(), KNeighborsClassifier()]\n",
    "VectorizeAndClassify(vectorizers_list, classifiers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2mfQKgl9RN3"
   },
   "source": [
    "#Разделим выборку на обучающую и тестовую и проверим решение для лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "m77McUr1uylj"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups['data'], newsgroups['target'], test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "7g6e4RKBvIHn"
   },
   "outputs": [],
   "source": [
    "def sentiment(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YcvoZrEgvFRk",
    "outputId": "92672e4d-101c-4719-f1be-414505d5ab38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0 \t 0.9290322580645162\n",
      "1 \t 0.9675090252707581\n",
      "2 \t 0.9026845637583892\n",
      "3 \t 0.9245901639344263\n"
     ]
    }
   ],
   "source": [
    "sentiment(CountVectorizer(), LinearSVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8gze-2y9bRl"
   },
   "source": [
    "#Работа с векторными представлениями слов с использованием word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "v7Y1WfrRwAWR"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "TatHWijIwB7r"
   },
   "outputs": [],
   "source": [
    "model_path = 'ruscorpora_mystem_cbow_300_2_2015.bin.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "yqBiwzzlwE9W"
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(model_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "LgDxS_I6wIMh"
   },
   "outputs": [],
   "source": [
    "words = ['холод_S', 'мороз_S', 'береза_S', 'сосна_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zy5v9XQQxHm1",
    "outputId": "54bb52cc-32ad-4c90-d424-016ca2c31efb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "СЛОВО - холод_S\n",
      "5 ближайших соседей слова:\n",
      "стужа_S => 0.7676383852958679\n",
      "сырость_S => 0.6338975429534912\n",
      "жара_S => 0.6089427471160889\n",
      "мороз_S => 0.589036762714386\n",
      "озноб_S => 0.5776054859161377\n",
      "\n",
      "СЛОВО - мороз_S\n",
      "5 ближайших соседей слова:\n",
      "стужа_S => 0.6425478458404541\n",
      "морозец_S => 0.5947279930114746\n",
      "холод_S => 0.589036762714386\n",
      "жара_S => 0.5522176623344421\n",
      "снегопад_S => 0.5083199143409729\n",
      "\n",
      "СЛОВО - береза_S\n",
      "5 ближайших соседей слова:\n",
      "сосна_S => 0.7943246960639954\n",
      "тополь_S => 0.7562226057052612\n",
      "дуб_S => 0.7440178394317627\n",
      "дерево_S => 0.7373415231704712\n",
      "клен_S => 0.7105200886726379\n",
      "\n",
      "СЛОВО - сосна_S\n",
      "5 ближайших соседей слова:\n",
      "береза_S => 0.7943247556686401\n",
      "дерево_S => 0.758143424987793\n",
      "лиственница_S => 0.7478148937225342\n",
      "дуб_S => 0.7412480711936951\n",
      "ель_S => 0.7363824844360352\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    if word in model:\n",
    "        print('\\nСЛОВО - {}'.format(word))\n",
    "        print('5 ближайших соседей слова:')\n",
    "        for word, sim in model.most_similar(positive=[word], topn=5):\n",
    "            print('{} => {}'.format(word, sim))\n",
    "    else:\n",
    "        print('Слово \"{}\" не найдено в модели'.format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0RDfHMr9sgv"
   },
   "source": [
    "#Находим близость между словами и строим аналогии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cTsFYXWxL9K",
    "outputId": "6d9ab0bc-c284-430e-ca8f-62983e5b1821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79432476\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('сосна_S', 'береза_S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DI2D3nmtxMao",
    "outputId": "08315ebc-1eb3-40cd-b440-264966de1772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('сырость_S', 0.5040210485458374), ('стылость_S', 0.46336129307746887), ('голод_S', 0.4604816436767578), ('зной_S', 0.45904630422592163), ('скука_S', 0.4489358067512512), ('жара_S', 0.44645124673843384), ('усталость_S', 0.4218570291996002), ('озноб_S', 0.41469815373420715), ('духота_S', 0.4099087715148926), ('неуют_S', 0.40298786759376526)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(positive=['холод_S', 'стужа_S'], negative=['мороз_S']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3dZXqKE9zrt"
   },
   "source": [
    "#Обучим word2vec на наборе данных \"fetch_20newsgroups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIABoRcH5tWG",
    "outputId": "6cd579b0-92eb-417c-bcd3-eb591332e145"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dnikolskiy/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "jZbwRKof5zb9"
   },
   "outputs": [],
   "source": [
    "categories = [\"rec.motorcycles\", \"rec.sport.baseball\", \"sci.electronics\",\"sci.med\"]\n",
    "newsgroups = fetch_20newsgroups(subset='train', categories=categories)\n",
    "data = newsgroups['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "qXFAWpOR6akB"
   },
   "outputs": [],
   "source": [
    "# Подготовим корпус\n",
    "corpus = []\n",
    "stop_words = stopwords.words('english')\n",
    "tok = WordPunctTokenizer()\n",
    "for line in newsgroups['data']:\n",
    "    line1 = line.strip().lower()\n",
    "    line1 = re.sub(\"[^a-zA-Z]\",\" \", line1)\n",
    "    text_tok = tok.tokenize(line1)\n",
    "    text_tok1 = [w for w in text_tok if not w in stop_words]\n",
    "    corpus.append(text_tok1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-8AkEoW6vg4",
    "outputId": "80b3438c-6a6d-4d52-f30e-027bfdb09af9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nrmendel',\n",
       "  'unix',\n",
       "  'amherst',\n",
       "  'edu',\n",
       "  'nathaniel',\n",
       "  'mendell',\n",
       "  'subject',\n",
       "  'bike',\n",
       "  'advice',\n",
       "  'organization',\n",
       "  'amherst',\n",
       "  'college',\n",
       "  'x',\n",
       "  'newsreader',\n",
       "  'tin',\n",
       "  'version',\n",
       "  'pl',\n",
       "  'lines',\n",
       "  'ummm',\n",
       "  'bikes',\n",
       "  'kx',\n",
       "  'suggest',\n",
       "  'look',\n",
       "  'zx',\n",
       "  'since',\n",
       "  'horsepower',\n",
       "  'whereas',\n",
       "  'might',\n",
       "  'bit',\n",
       "  'much',\n",
       "  'sincerely',\n",
       "  'nathaniel',\n",
       "  'zx',\n",
       "  'dod',\n",
       "  'ama'],\n",
       " ['grante',\n",
       "  'aquarius',\n",
       "  'rosemount',\n",
       "  'com',\n",
       "  'grant',\n",
       "  'edwards',\n",
       "  'subject',\n",
       "  'krillean',\n",
       "  'photography',\n",
       "  'reply',\n",
       "  'grante',\n",
       "  'aquarius',\n",
       "  'rosemount',\n",
       "  'com',\n",
       "  'grant',\n",
       "  'edwards',\n",
       "  'organization',\n",
       "  'rosemount',\n",
       "  'inc',\n",
       "  'lines',\n",
       "  'nntp',\n",
       "  'posting',\n",
       "  'host',\n",
       "  'aquarius',\n",
       "  'stgprao',\n",
       "  'st',\n",
       "  'unocal',\n",
       "  'com',\n",
       "  'richard',\n",
       "  'ottolini',\n",
       "  'writes',\n",
       "  'living',\n",
       "  'things',\n",
       "  'maintain',\n",
       "  'small',\n",
       "  'electric',\n",
       "  'fields',\n",
       "  'enhance',\n",
       "  'certain',\n",
       "  'chemical',\n",
       "  'reactions',\n",
       "  'promote',\n",
       "  'communication',\n",
       "  'states',\n",
       "  'cell',\n",
       "  'communicate',\n",
       "  'cells',\n",
       "  'nervous',\n",
       "  'system',\n",
       "  'specialized',\n",
       "  'example',\n",
       "  'perhaps',\n",
       "  'uses',\n",
       "  'true',\n",
       "  'electric',\n",
       "  'fields',\n",
       "  'change',\n",
       "  'location',\n",
       "  'time',\n",
       "  'large',\n",
       "  'organism',\n",
       "  'also',\n",
       "  'true',\n",
       "  'special',\n",
       "  'photographic',\n",
       "  'techniques',\n",
       "  'applying',\n",
       "  'external',\n",
       "  'fields',\n",
       "  'kirillian',\n",
       "  'photography',\n",
       "  'interact',\n",
       "  'fields',\n",
       "  'resistances',\n",
       "  'caused',\n",
       "  'fields',\n",
       "  'make',\n",
       "  'interesting',\n",
       "  'pictures',\n",
       "  'really',\n",
       "  'kirlian',\n",
       "  'photography',\n",
       "  'taking',\n",
       "  'pictures',\n",
       "  'corona',\n",
       "  'discharge',\n",
       "  'objects',\n",
       "  'animate',\n",
       "  'inanimate',\n",
       "  'fields',\n",
       "  'applied',\n",
       "  'objects',\n",
       "  'millions',\n",
       "  'times',\n",
       "  'larger',\n",
       "  'biologically',\n",
       "  'created',\n",
       "  'fields',\n",
       "  'want',\n",
       "  'record',\n",
       "  'biologically',\n",
       "  'created',\n",
       "  'electric',\n",
       "  'fields',\n",
       "  'got',\n",
       "  'use',\n",
       "  'low',\n",
       "  'noise',\n",
       "  'high',\n",
       "  'gain',\n",
       "  'sensors',\n",
       "  'typical',\n",
       "  'eegs',\n",
       "  'ekgs',\n",
       "  'kirlian',\n",
       "  'photography',\n",
       "  'phun',\n",
       "  'physics',\n",
       "  'type',\n",
       "  'stuff',\n",
       "  'right',\n",
       "  'soaking',\n",
       "  'chunks',\n",
       "  'extra',\n",
       "  'fine',\n",
       "  'steel',\n",
       "  'wool',\n",
       "  'liquid',\n",
       "  'oxygen',\n",
       "  'hitting',\n",
       "  'hammer',\n",
       "  'like',\n",
       "  'kirlean',\n",
       "  'setup',\n",
       "  'fun',\n",
       "  'possibly',\n",
       "  'dangerous',\n",
       "  'perhaps',\n",
       "  'pictures',\n",
       "  'diagonistic',\n",
       "  'disease',\n",
       "  'problems',\n",
       "  'organisms',\n",
       "  'better',\n",
       "  'understood',\n",
       "  'perhaps',\n",
       "  'probably',\n",
       "  'grant',\n",
       "  'edwards',\n",
       "  'yow',\n",
       "  'vote',\n",
       "  'rosemount',\n",
       "  'inc',\n",
       "  'well',\n",
       "  'tapered',\n",
       "  'half',\n",
       "  'cocked',\n",
       "  'ill',\n",
       "  'conceived',\n",
       "  'grante',\n",
       "  'aquarius',\n",
       "  'rosemount',\n",
       "  'com',\n",
       "  'tax',\n",
       "  'deferred'],\n",
       " ['liny',\n",
       "  'sun',\n",
       "  'scri',\n",
       "  'fsu',\n",
       "  'edu',\n",
       "  'nemo',\n",
       "  'subject',\n",
       "  'bates',\n",
       "  'method',\n",
       "  'myopia',\n",
       "  'reply',\n",
       "  'lin',\n",
       "  'ray',\n",
       "  'met',\n",
       "  'fsu',\n",
       "  'edu',\n",
       "  'distribution',\n",
       "  'na',\n",
       "  'organization',\n",
       "  'scri',\n",
       "  'florida',\n",
       "  'state',\n",
       "  'university',\n",
       "  'lines',\n",
       "  'bates',\n",
       "  'method',\n",
       "  'work',\n",
       "  'first',\n",
       "  'heard',\n",
       "  'newsgroup',\n",
       "  'several',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'got',\n",
       "  'hold',\n",
       "  'book',\n",
       "  'improve',\n",
       "  'sight',\n",
       "  'simple',\n",
       "  'daily',\n",
       "  'drills',\n",
       "  'relaxation',\n",
       "  'margaret',\n",
       "  'corbett',\n",
       "  'authorized',\n",
       "  'instructor',\n",
       "  'bates',\n",
       "  'method',\n",
       "  'published',\n",
       "  'talks',\n",
       "  'vision',\n",
       "  'improvement',\n",
       "  'relaxation',\n",
       "  'exercise',\n",
       "  'study',\n",
       "  'whether',\n",
       "  'method',\n",
       "  'actually',\n",
       "  'works',\n",
       "  'works',\n",
       "  'actually',\n",
       "  'shortening',\n",
       "  'previously',\n",
       "  'elongated',\n",
       "  'eyeball',\n",
       "  'increasing',\n",
       "  'lens',\n",
       "  'ability',\n",
       "  'flatten',\n",
       "  'order',\n",
       "  'compensate',\n",
       "  'long',\n",
       "  'eyeball',\n",
       "  'since',\n",
       "  'myopia',\n",
       "  'result',\n",
       "  'eyeball',\n",
       "  'elongation',\n",
       "  'seems',\n",
       "  'logical',\n",
       "  'approach',\n",
       "  'correction',\n",
       "  'find',\n",
       "  'way',\n",
       "  'reverse',\n",
       "  'process',\n",
       "  'e',\n",
       "  'shorten',\n",
       "  'somehow',\n",
       "  'preferably',\n",
       "  'non',\n",
       "  'surgically',\n",
       "  'recent',\n",
       "  'studies',\n",
       "  'find',\n",
       "  'know',\n",
       "  'rk',\n",
       "  'works',\n",
       "  'changing',\n",
       "  'curvature',\n",
       "  'cornea',\n",
       "  'compensate',\n",
       "  'shape',\n",
       "  'eyeball',\n",
       "  'way',\n",
       "  'train',\n",
       "  'muscles',\n",
       "  'shorten',\n",
       "  'eyeball',\n",
       "  'back',\n",
       "  'correct',\n",
       "  'length',\n",
       "  'would',\n",
       "  'even',\n",
       "  'better',\n",
       "  'bates',\n",
       "  'idea',\n",
       "  'right',\n",
       "  'thanks',\n",
       "  'information'],\n",
       " ['mcovingt',\n",
       "  'aisun',\n",
       "  'ai',\n",
       "  'uga',\n",
       "  'edu',\n",
       "  'michael',\n",
       "  'covington',\n",
       "  'subject',\n",
       "  'buy',\n",
       "  'parts',\n",
       "  'time',\n",
       "  'nntp',\n",
       "  'posting',\n",
       "  'host',\n",
       "  'aisun',\n",
       "  'ai',\n",
       "  'uga',\n",
       "  'edu',\n",
       "  'organization',\n",
       "  'ai',\n",
       "  'programs',\n",
       "  'university',\n",
       "  'georgia',\n",
       "  'athens',\n",
       "  'lines',\n",
       "  'pricing',\n",
       "  'parts',\n",
       "  'reminds',\n",
       "  'something',\n",
       "  'chemist',\n",
       "  'said',\n",
       "  'gram',\n",
       "  'dye',\n",
       "  'costs',\n",
       "  'dollar',\n",
       "  'comes',\n",
       "  'liter',\n",
       "  'jar',\n",
       "  'also',\n",
       "  'costs',\n",
       "  'dollar',\n",
       "  'want',\n",
       "  'whole',\n",
       "  'barrel',\n",
       "  'also',\n",
       "  'costs',\n",
       "  'dollar',\n",
       "  'e',\n",
       "  'charge',\n",
       "  'almost',\n",
       "  'exclusively',\n",
       "  'packaging',\n",
       "  'delivering',\n",
       "  'chemical',\n",
       "  'particular',\n",
       "  'case',\n",
       "  'byproduct',\n",
       "  'cost',\n",
       "  'almost',\n",
       "  'nothing',\n",
       "  'intrinsically',\n",
       "  'michael',\n",
       "  'covington',\n",
       "  'associate',\n",
       "  'research',\n",
       "  'scientist',\n",
       "  'artificial',\n",
       "  'intelligence',\n",
       "  'programs',\n",
       "  'mcovingt',\n",
       "  'ai',\n",
       "  'uga',\n",
       "  'edu',\n",
       "  'university',\n",
       "  'georgia',\n",
       "  'phone',\n",
       "  'athens',\n",
       "  'georgia',\n",
       "  'u',\n",
       "  'amateur',\n",
       "  'radio',\n",
       "  'n',\n",
       "  'tmi'],\n",
       " ['tammy',\n",
       "  'vandenboom',\n",
       "  'launchpad',\n",
       "  'unc',\n",
       "  'edu',\n",
       "  'tammy',\n",
       "  'vandenboom',\n",
       "  'subject',\n",
       "  'sore',\n",
       "  'spot',\n",
       "  'testicles',\n",
       "  'nntp',\n",
       "  'posting',\n",
       "  'host',\n",
       "  'lambada',\n",
       "  'oit',\n",
       "  'unc',\n",
       "  'edu',\n",
       "  'organization',\n",
       "  'university',\n",
       "  'north',\n",
       "  'carolina',\n",
       "  'extended',\n",
       "  'bulletin',\n",
       "  'board',\n",
       "  'service',\n",
       "  'distribution',\n",
       "  'na',\n",
       "  'lines',\n",
       "  'husband',\n",
       "  'woke',\n",
       "  'three',\n",
       "  'days',\n",
       "  'ago',\n",
       "  'small',\n",
       "  'sore',\n",
       "  'spot',\n",
       "  'spot',\n",
       "  'size',\n",
       "  'nickel',\n",
       "  'one',\n",
       "  'testicles',\n",
       "  'bottom',\n",
       "  'side',\n",
       "  'knots',\n",
       "  'lumps',\n",
       "  'little',\n",
       "  'sore',\n",
       "  'spot',\n",
       "  'says',\n",
       "  'reminds',\n",
       "  'bruise',\n",
       "  'feels',\n",
       "  'recollection',\n",
       "  'hitting',\n",
       "  'anything',\n",
       "  'like',\n",
       "  'would',\n",
       "  'cause',\n",
       "  'bruise',\n",
       "  'asssures',\n",
       "  'remember',\n",
       "  'something',\n",
       "  'like',\n",
       "  'clues',\n",
       "  'might',\n",
       "  'somewhat',\n",
       "  'hypochondriac',\n",
       "  'sp',\n",
       "  'sure',\n",
       "  'gonna',\n",
       "  'die',\n",
       "  'thanks',\n",
       "  'opinions',\n",
       "  'expressed',\n",
       "  'necessarily',\n",
       "  'university',\n",
       "  'north',\n",
       "  'carolina',\n",
       "  'chapel',\n",
       "  'hill',\n",
       "  'campus',\n",
       "  'office',\n",
       "  'information',\n",
       "  'technology',\n",
       "  'experimental',\n",
       "  'bulletin',\n",
       "  'board',\n",
       "  'service',\n",
       "  'internet',\n",
       "  'launchpad',\n",
       "  'unc',\n",
       "  'edu']]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tLEebm1K7L41",
    "outputId": "62ff33f1-ceb1-40b3-b4fb-ec4f3726fd22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.76 s, sys: 19.1 ms, total: 3.78 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%time model_imdb = word2vec.Word2Vec(corpus, workers=4, min_count=10, window=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klyXfeAR7SeB",
    "outputId": "c83297fb-ac6d-41af-abd8-34b4a138c7f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('etc', 0.9759538173675537), ('voltage', 0.9697504639625549), ('buy', 0.9697079658508301), ('circuit', 0.9695694446563721), ('work', 0.9691796898841858)]\n"
     ]
    }
   ],
   "source": [
    "# Проверим, что модель обучилась\n",
    "print(model_imdb.wv.most_similar(positive=['find'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "LjM2Ehr-7W0K"
   },
   "outputs": [],
   "source": [
    "def sentiment_2(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yUJ1Ynz_2DJ"
   },
   "source": [
    "#Проверка качества работы модели word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "cL1m4h3M7eMo"
   },
   "outputs": [],
   "source": [
    "class EmbeddingVectorizer(object):\n",
    "    '''\n",
    "    Для текста усредним вектора входящих в него слов\n",
    "    '''\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.size = model.vector_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean(\n",
    "            [self.model[w] for w in words if w in self.model] \n",
    "            or [np.zeros(self.size)], axis=0)\n",
    "            for words in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "iNEtVYom7iCJ"
   },
   "outputs": [],
   "source": [
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "BLZ9TMCd7ksg"
   },
   "outputs": [],
   "source": [
    "# Обучающая и тестовая выборки\n",
    "boundary = 1500\n",
    "X_train = corpus[:boundary] \n",
    "X_test = corpus[boundary:]\n",
    "y_train = newsgroups['target'][:boundary]\n",
    "y_test = newsgroups['target'][boundary:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBvQx4dv73ls",
    "outputId": "b2fdd721-f8c8-4075-ee39-d1dbbf49c217"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnikolskiy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0 \t 0.868421052631579\n",
      "1 \t 0.9368932038834952\n",
      "2 \t 0.8073394495412844\n",
      "3 \t 0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "sentiment_2(EmbeddingVectorizer(model_imdb.wv), LogisticRegression(C=5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnUKW0uhFBJa"
   },
   "source": [
    "### *Как видно из результатов проверки качества моделей, лучшее качество показал CountVectorizer*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled12.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "bbdcf83d58750803bddb0838f4afd2350dc6ac29aa7aec92f3be190ea6031456"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
